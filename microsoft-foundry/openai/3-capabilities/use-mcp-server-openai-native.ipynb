{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323056fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_0bca83ff5eb7ed76006964a365dc9881939dd881a83f252e7a\",\n",
      "  \"created_at\": 1768203109.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"mcpl_0bca83ff5eb7ed76006964a365eba4819396057e792ea10379\",\n",
      "      \"server_label\": \"Microsoft_Learn_MCP_Server\",\n",
      "      \"tools\": [\n",
      "        {\n",
      "          \"input_schema\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "              \"query\": {\n",
      "                \"description\": \"a query or topic about Microsoft/Azure products, services, platforms, developer tools, frameworks, or APIs\",\n",
      "                \"type\": \"string\",\n",
      "                \"default\": null\n",
      "              },\n",
      "              \"question\": {\n",
      "                \"description\": \"this parameter is no longer used, use query instead.\",\n",
      "                \"type\": \"string\",\n",
      "                \"default\": null\n",
      "              }\n",
      "            }\n",
      "          },\n",
      "          \"name\": \"microsoft_docs_search\",\n",
      "          \"annotations\": {\n",
      "            \"read_only\": true\n",
      "          },\n",
      "          \"description\": \"Search official Microsoft/Azure documentation to find the most relevant and trustworthy content for a user's query. This tool returns up to 10 high-quality content chunks (each max 500 tokens), extracted from Microsoft Learn and other official sources. Each result includes the article title, URL, and a self-contained content excerpt optimized for fast retrieval and reasoning. Always use this tool to quickly ground your answers in accurate, first-party Microsoft/Azure knowledge.\\n\\nThe `question` parameter is no longer used, use `query` instead.\\n\\n## Follow-up Pattern\\nTo ensure completeness, use microsoft_docs_fetch when high-value pages are identified by search. The fetch tool complements search by providing the full detail. This is a required step for comprehensive results.\"\n",
      "        },\n",
      "        {\n",
      "          \"input_schema\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "              \"query\": {\n",
      "                \"description\": \"a descriptive query, SDK name, method name or code snippet related to Microsoft/Azure products, services, platforms, developer tools, frameworks, APIs or SDKs\",\n",
      "                \"type\": \"string\"\n",
      "              },\n",
      "              \"language\": {\n",
      "                \"description\": \"Optional parameter specifying the programming language of code snippets to retrieve. Can significantly improve search quality if provided. Eligible values: csharp javascript typescript python powershell azurecli al sql java kusto cpp go rust ruby php\",\n",
      "                \"type\": \"string\",\n",
      "                \"default\": null\n",
      "              }\n",
      "            },\n",
      "            \"required\": [\n",
      "              \"query\"\n",
      "            ]\n",
      "          },\n",
      "          \"name\": \"microsoft_code_sample_search\",\n",
      "          \"annotations\": {\n",
      "            \"read_only\": true\n",
      "          },\n",
      "          \"description\": \"Search for code snippets and examples in official Microsoft Learn documentation. This tool retrieves relevant code samples from Microsoft documentation pages providing developers with practical implementation examples and best practices for Microsoft/Azure products and services related coding tasks. This tool will help you use the **LATEST OFFICIAL** code snippets to empower coding capabilities.\\n\\n## When to Use This Tool\\n- When you are going to provide sample Microsoft/Azure related code snippets in your answers.\\n- When you are **generating any Microsoft/Azure related code**.\\n\\n## Usage Pattern\\nInput a descriptive query, or SDK/class/method name to retrieve related code samples. The optional parameter `language` can help to filter results.\\n\\nEligible values for `language` parameter include: csharp javascript typescript python powershell azurecli al sql java kusto cpp go rust ruby php\"\n",
      "        },\n",
      "        {\n",
      "          \"input_schema\": {\n",
      "            \"type\": \"object\",\n",
      "            \"properties\": {\n",
      "              \"url\": {\n",
      "                \"description\": \"URL of the Microsoft documentation page to read\",\n",
      "                \"type\": \"string\"\n",
      "              }\n",
      "            },\n",
      "            \"required\": [\n",
      "              \"url\"\n",
      "            ]\n",
      "          },\n",
      "          \"name\": \"microsoft_docs_fetch\",\n",
      "          \"annotations\": {\n",
      "            \"read_only\": true\n",
      "          },\n",
      "          \"description\": \"Fetch and convert a Microsoft Learn documentation page to markdown format. This tool retrieves the latest complete content of Microsoft documentation pages including Azure, .NET, Microsoft 365, and other Microsoft technologies.\\n\\n## When to Use This Tool\\n- When search results provide incomplete information or truncated content\\n- When you need complete step-by-step procedures or tutorials\\n- When you need troubleshooting sections, prerequisites, or detailed explanations\\n- When search results reference a specific page that seems highly relevant\\n- For comprehensive guides that require full context\\n\\n## Usage Pattern\\nUse this tool AFTER microsoft_docs_search when you identify specific high-value pages that need complete content. The search tool gives you an overview; this tool gives you the complete picture.\\n\\n## URL Requirements\\n- The URL must be a valid link from the microsoft.com domain.\\n\\n## Output Format\\nmarkdown with headings, code blocks, tables, and links preserved.\"\n",
      "        }\n",
      "      ],\n",
      "      \"type\": \"mcp_list_tools\",\n",
      "      \"error\": null\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"mcp_0bca83ff5eb7ed76006964a3678b54819386eac7b656b564ee\",\n",
      "      \"arguments\": \"{\\\"query\\\":\\\"Microsoft Foundry Anthropic Claude 4.5\\\",\\\"question\\\":\\\"Microsoft Foundry„Åß„Éõ„Çπ„Éà„Åï„Çå„ÇãAnthropic Claude 4.5„Å´„Å§„ÅÑ„Å¶Ëß£Ë™¨„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\\\"}\",\n",
      "      \"name\": \"microsoft_docs_search\",\n",
      "      \"server_label\": \"Microsoft_Learn_MCP_Server\",\n",
      "      \"type\": \"mcp_call\",\n",
      "      \"approval_request_id\": null,\n",
      "      \"error\": null,\n",
      "      \"output\": \"{\\\"results\\\": [{\\\"title\\\": \\\"Deploy and use Claude models in Microsoft Foundry (preview)\\\", \\\"content\\\": \\\"# Deploy and use Claude models in Microsoft Foundry (preview)\\\\n## Available Claude models\\\\nFoundry supports Claude Opus 4.5, Claude Sonnet 4.5, Claude Haiku 4.5, and Claude Opus 4.1 models through global standard deployment. These models have key capabilities that include:\\\\n1. **Extended thinking**: Extended thinking gives Claude enhanced reasoning capabilities for complex tasks.\\\\n2. **Image and text input**: Strong vision capabilities that enable the models to process images and return text outputs for analyzing and understanding charts, graphs, technical diagrams, reports, and other visual assets.\\\\n3. **Code generation**: Advanced thinking that includes code generation, analysis, and debugging for Claude Sonnet 4.5 and Claude Opus 4.1.\\\\nFor more details about the model capabilities, see [capabilities of Claude models](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-from-partners?view=foundry-classic#anthropic).\\\\n#### Claude Opus 4.5 (preview)\\\\nClaude Opus 4.5 is Anthropic's most intelligent model, and an industry leader across coding, agents, computer use, and enterprise workflows. With a 200K token context window and 64K max output, Opus 4.5 is ideal for production code, sophisticated agents, office tasks, financial analysis, cybersecurity, and computer use.\\\\n#### Claude Sonnet 4.5 (preview)\\\\nClaude Sonnet 4.5 is a highly capable model designed for building real-world agents and handling complex, long-horizon tasks. It offers a strong balance of speed and cost for high-volume use cases. Sonnet 4.5 also provides advanced accuracy for computer use, enabling developers to direct Claude to use computers the way people do.\\\\n#### Claude Haiku 4.5 (preview)\\\\nClaude Haiku 4.5 delivers near-frontier performance for a wide range of use cases. It stands out as one of the best coding and agent models, with the right speed and cost to power free products and scaled sub-agents.\\\\n#### Claude Opus 4.1 (preview)\\\\nClaude Opus 4.1 is an industry leader for coding. It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, significantly expanding what AI agents can solve.\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/how-to/use-foundry-models-claude?view=foundry-classic#available-claude-models\\\"}, {\\\"title\\\": \\\"Deploy and use Claude models in Microsoft Foundry (preview)\\\", \\\"content\\\": \\\"# Deploy and use Claude models in Microsoft Foundry (preview)\\\\nNote\\\\nThis document refers to the [Microsoft Foundry (classic)](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-foundry?view=foundry-classic#microsoft-foundry-portals) portal.\\\\n\\\\ud83d\\\\udd04 [Switch to the Microsoft Foundry (new) documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/how-to/use-foundry-models-claude?view=foundry&preserve-view=true) if you're using the new portal.\\\\nThis article explains how to deploy and use the latest Claude models in Foundry, including Claude Opus 4.5, Claude Sonnet 4.5, Claude Haiku 4.5, and Claude Opus 4.1. Anthropic's flagship product is Claude, a frontier AI model useful for complex tasks such as coding, agents, financial analysis, research, and office tasks. Claude delivers exceptional performance while maintaining high safety standards.\\\\nImportant\\\\nTo use Claude models in Microsoft Foundry, you need a paid Azure subscription with a billing account in a [country or region](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/deploy-models-serverless-availability?view=foundry-classic#region-availability) where Anthropic offers the models for purchase. The following paid subscription types are currently restricted: Cloud Solution Providers (CSP), sponsored accounts with Azure credits, enterprise accounts in Singapore and South Korea, and Microsoft accounts.\\\\nFor a list of common subscription-related errors, see [Common error messages and solutions](https://learn.microsoft.com/en-us/marketplace/purchase-saas-offer-in-azure-portal#common-error-messages-and-solutions).\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/how-to/use-foundry-models-claude?view=foundry-classic\\\"}, {\\\"title\\\": \\\"What's new in model router in Microsoft Foundry Models?\\\", \\\"content\\\": \\\"# What's new in model router in Microsoft Foundry Models?\\\\nThis article provides a summary of the latest releases and major documentation updates for Azure model router.\\\\nNote\\\\nThis document refers to the [Microsoft Foundry (classic)](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-foundry?view=foundry-classic#microsoft-foundry-portals) portal.\\\\n\\\\ud83d\\\\udd04 [Switch to the Microsoft Foundry (new) documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/whats-new-model-router?view=foundry&preserve-view=true) if you're using the new portal.\\\\n## November 2025\\\\n### Anthropic models added\\\\nVersion `2025-11-18` of model router adds support for three Anthropic models: `claude-haiku-4-5`, `claude-opus-4-1`, and `claude-sonnet-4-5`. To include these in your model router deployment, you need to first deploy them yourself to your Foundry resource (see [Deploy and use Claude models](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/how-to/use-foundry-models-claude?view=foundry&tabs=python)). Then enable them with [model subset configuration](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/model-router?view=foundry) in your model router deployment.\\\\n### Model router GA version\\\\nA new model router model is now available. Version `2025-11-18` includes support for all underlying models in previous versions, as well as 10 new language models.\\\\nIt also includes new features that make it more versatile and effective.\\\\n1. **Routing profiles** let you skew model router's choices to optimize for quality or cost while maintaining a baseline level of performance.\\\\n2. Model router supports **custom subsets**: you can specify which underlying models to include in routing decisions. This gives you more control over cost, compliance, and performance characteristics.\\\\nFor more information on model router and its capabilities, see the [Model router concepts guide](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/model-router?view=foundry-classic).\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/whats-new-model-router?view=foundry-classic\\\"}, {\\\"title\\\": \\\"Deploy and use Claude models in Microsoft Foundry (preview)\\\", \\\"content\\\": \\\"# Deploy and use Claude models in Microsoft Foundry (preview)\\\\n## Responsible AI considerations\\\\nWhen using Claude models in Foundry, consider these responsible AI practices:\\\\n1. Configure AI content safety during model inference, as Foundry doesn't provide built-in content filtering for Claude models at deployment time. To learn how to create and use content filters, see [Configure content filtering for Foundry Models](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/how-to/configure-content-filters?view=foundry-classic).\\\\n2. Ensure your applications comply with [Anthropic's Acceptable Use Policy](https://www.anthropic.com/legal/aup). Also, see details of safety evaluations for [Claude Opus 4.5](http://www.anthropic.com/claude-opus-4-5-system-card), [Claude Haiku 4.5](https://assets.anthropic.com/m/99128ddd009bdcb/Claude-Haiku-4-5-System-Card.pdf), [Claude Opus 4.1](https://assets.anthropic.com/m/4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf), and [Claude Sonnet 4.5](https://assets.anthropic.com/m/12f214efcc2f457a/original/Claude-Sonnet-4-5-System-Card.pdf).\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/how-to/use-foundry-models-claude?view=foundry-classic#responsible-ai-considerations\\\"}, {\\\"title\\\": \\\"Deploy and use Claude models in Microsoft Foundry (preview)\\\", \\\"content\\\": \\\"# Deploy and use Claude models in Microsoft Foundry (preview)\\\\n## Work with Claude models\\\\nOnce deployed, you have some options for interacting with Claude models to generate text responses:\\\\n1. Use the [Anthropic SDKs](https://docs.claude.com/en/api/client-sdks) and the following Claude APIs:\\\\n1.1. [Messages API](https://docs.claude.com/en/api/messages) to send a structured list of input messages with text and/or image content, and the model generates the next message in the conversation.\\\\n1.2. [Token Count API](https://docs.claude.com/en/api/messages-count-tokens) to count the number of tokens in a message.\\\\n1.3. [Files API](https://docs.claude.com/en/api/files-create) to upload and manage files to use with the Claude API without having to re-upload content with each request.\\\\n1.4. [Skills API](https://docs.claude.com/en/api/skills/create-skill) to create custom skills for Claude AI.\\\\n### Use the Messages API to work with Claude models\\\\nThe following examples show how to **use the Messages API** to send requests to Claude Sonnet 4.5, by using both Microsoft Entra ID authentication and API key authentication methods. To work with your deployed model, you need these items:\\\\n1. Your base URL, which is of the form `https://<resource name>.services.ai.azure.com/anthropic`.\\\\n2. Your target URI from your deployment details, which is of the form `https://<resource name>.services.ai.azure.com/anthropic/v1/messages`.\\\\n3. Microsoft Entra ID for keyless authentication or your deployment's API key for API authentication.\\\\n4. Deployment name you chose during deployment creation. This name can be different from the model ID.\\\\n**Python**\\\\n#### Use Microsoft Entra ID authentication\\\\nFor Messages API endpoints, use your base URL with Microsoft Entra ID authentication.\\\\n1. **Install the Azure Identity client library**: You need to install this library to use the `DefaultAzureCredential`. Authorization is easiest when you use `DefaultAzureCredential`, as it finds the best credential to use in its running environment.\\\\n```bash\\\\n pip install azure.identity\\\\n```\\\\n Set the values of the client ID, tenant ID, and client secret of the Microsoft Entra ID application as environment variables: `AZURE_CLIENT_ID`, `AZURE_TENANT_ID`, `AZURE_CLIENT_SECRET`.\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/how-to/use-foundry-models-claude?view=foundry-classic#work-with-claude-models\\\"}, {\\\"title\\\": \\\"Anthropic Agents (programming-language-csharp)\\\", \\\"content\\\": \\\"# Anthropic Agents (programming-language-csharp)\\\\nThe Microsoft Agent Framework supports creating agents that use [Anthropic's Claude models](https://www.anthropic.com/claude).\\\\n## Getting Started\\\\nAdd the required NuGet packages to your project.\\\\n```powershell\\\\ndotnet add package Microsoft.Agents.AI.Anthropic --prerelease\\\\n```\\\\nIf you're using Azure Foundry, also add:\\\\n```powershell\\\\ndotnet add package Anthropic.Foundry --prerelease\\\\ndotnet add package Azure.Identity\\\\n```\\\\n## Configuration\\\\n### Environment Variables\\\\nSet up the required environment variables for Anthropic authentication:\\\\n```powershell\\\\n# Required for Anthropic API access\\\\n$env:ANTHROPIC_API_KEY=\\\\\\\"your-anthropic-api-key\\\\\\\"\\\\n$env:ANTHROPIC_DEPLOYMENT_NAME=\\\\\\\"claude-haiku-4-5\\\\\\\"  # or your preferred model\\\\n```\\\\nYou can get an API key from the [Anthropic Console](https://console.anthropic.com/).\\\\n### For Azure Foundry with API Key\\\\n```powershell\\\\n$env:ANTHROPIC_RESOURCE=\\\\\\\"your-foundry-resource-name\\\\\\\"  # Subdomain before .services.ai.azure.com\\\\n$env:ANTHROPIC_API_KEY=\\\\\\\"your-anthropic-api-key\\\\\\\"\\\\n$env:ANTHROPIC_DEPLOYMENT_NAME=\\\\\\\"claude-haiku-4-5\\\\\\\"\\\\n```\\\\n### For Azure Foundry with Azure CLI\\\\n```powershell\\\\n$env:ANTHROPIC_RESOURCE=\\\\\\\"your-foundry-resource-name\\\\\\\"  # Subdomain before .services.ai.azure.com\\\\n$env:ANTHROPIC_DEPLOYMENT_NAME=\\\\\\\"claude-haiku-4-5\\\\\\\"\\\\n```\\\\nNote\\\\nWhen using Azure Foundry with Azure CLI, make sure you're logged in with `az login` and have access to the Azure Foundry resource. For more information, see the [Azure CLI documentation](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively).\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/anthropic-agent\\\"}, {\\\"title\\\": \\\"Foundry Models from partners and community\\\", \\\"content\\\": \\\"# Foundry Models from partners and community\\\\n## Anthropic\\\\n| Model | Type | Capabilities | Project type| \\\\n|  --- | --- | --- | ---  |\\\\n| [claude-haiku-4-5](https://aka.ms/claude-haiku-4-5)**(Preview)** | Messages | - **Input:** text and image - **Output:** text (64,000 max tokens) - **Context window:** 200,000 - **Languages:**`en`, `fr`, `ar`, `zh`, `ja`, `ko`, `es`, `hi` - **Tool calling:** Yes (file search and code execution) - **Response formats:** Text, JSON | Foundry, Hub-based |\\\\n| [claude-opus-4-1](https://aka.ms/claude-opus-4-1)**(Preview)** | Messages | - **Input:** text, image, and code - **Output:** text (32,000 max tokens) - **Context window:** 200,000 - **Languages:**`en`, `fr`, `ar`, `zh`, `ja`, `ko`, `es`, `hi` - **Tool calling:** Yes (file search and code execution) - **Response formats:** Text, JSON | Foundry, Hub-based |\\\\n| [claude-sonnet-4-5](https://aka.ms/claude-sonnet-4-5)**(Preview)** | Messages | - **Input:** text, image, and code - **Output:** text (max 64,000 tokens) - **Context window:** 200,000 - **Languages:**`en`, `fr`, `ar`, `zh`, `ja`, `ko`, `es`, `hi` - **Tool calling:** Yes (file search and code execution) - **Response formats:** Text, JSON | Foundry, Hub-based |\\\\n| [claude-opus-4-5](https://aka.ms/claude-opus-4-5)**(Preview)** | Messages | - **Input:** text and imag, and code - **Output:** text (64,000 max tokens) - **Context window:** 200,000 - **Languages:**`en`, `fr`, `ar`, `zh`, `ja`, `ko`, `es`, `hi` - **Tool calling:** Yes (file search and code execution) - **Response formats:** Text, JSON | Foundry, Hub-based |\\\\n\\\\nSee [the Anthropic model collection in the Foundry portal](https://ai.azure.com/explore/models?&selectedCollection=anthropic/?cid=learnDocs).\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/concepts/models-from-partners?view=foundry-classic#anthropic\\\"}, {\\\"title\\\": \\\"Use model router for Microsoft Foundry\\\", \\\"content\\\": \\\"# Use model router for Microsoft Foundry\\\\nNote\\\\nThis document refers to the [Microsoft Foundry (classic)](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-foundry?view=foundry-classic#microsoft-foundry-portals) portal.\\\\n\\\\ud83d\\\\udd04 [Switch to the Microsoft Foundry (new) documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/model-router?view=foundry&preserve-view=true) if you're using the new portal.\\\\nModel router for Microsoft Foundry is a deployable AI chat model that selects the best large language model (LLM) to respond to a prompt in real time. It uses different preexisting models to deliver high performance and save on compute costs, all in one model deployment. To learn more about how model router works, its advantages, and limitations, see the [Model router concepts guide](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/model-router?view=foundry-classic).\\\\nUse model router through the Chat Completions API like you'd use a single base model such as GPT-4. Follow the same steps as in the [Chat completions guide](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/chatgpt).\\\\nTip\\\\nThe [Microsoft Foundry (new)](https://learn.microsoft.com/en-us/azure/ai-foundry/what-is-foundry?view=foundry-classic#microsoft-foundry-portals) portal offers enhanced configuration options for model router. [Switch to the Microsoft Foundry (new) documentation](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/model-router?view=foundry&preserve-view=true) to see the latest features.\\\\n## Supported underlying models\\\\nWith the `2025-11-18` version, Model Router adds nine new models including Anthropic's Claude, DeepSeek, Llama, Grok models to support a total of 18 models available for routing your prompts.\\\\nNote\\\\nYou don't need to separately deploy the supported LLMs for use with model router, with the exception of the Claude models. To use model router with your Claude models, first deploy them from the model catalog. The deployments will get invoked by Model router if they're selected for routing.\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/model-router?view=foundry-classic\\\"}, {\\\"title\\\": \\\"Anthropic Agents (programming-language-csharp)\\\", \\\"content\\\": \\\"# Anthropic Agents (programming-language-csharp)\\\\n## Creating an Anthropic Agent\\\\n### Basic Agent Creation (Anthropic Public API)\\\\nThe simplest way to create an Anthropic agent using the public API:\\\\n### Using Anthropic on Azure Foundry with API Key\\\\nAfter you've set up Anthropic on Azure Foundry, you can use it with API key authentication:\\\\n### Using Anthropic on Azure Foundry with Azure Credentials (Azure Cli Credential example)\\\\nFor environments where Azure Credentials are preferred:\\\\n## Using the Agent\\\\nThe agent is a standard `AIAgent` and supports all standard agent operations.\\\\nSee the [Agent getting started tutorials](https://learn.microsoft.com/en-us/agent-framework/tutorials/overview) for more information on how to run and interact with agents.\\\\n# Anthropic Agents (programming-language-python)\\\\nThe Microsoft Agent Framework supports creating agents that use [Anthropic's Claude models](https://www.anthropic.com/claude).\\\\n## Prerequisites\\\\nInstall the Microsoft Agent Framework Anthropic package.\\\\n```bash\\\\npip install agent-framework-anthropic --pre\\\\n```\\\\n## Configuration\\\\n### Environment Variables\\\\nSet up the required environment variables for Anthropic authentication:\\\\n```bash\\\\n# Required for Anthropic API access\\\\nANTHROPIC_API_KEY=\\\\\\\"your-anthropic-api-key\\\\\\\"\\\\nANTHROPIC_CHAT_MODEL_ID=\\\\\\\"claude-sonnet-4-5-20250929\\\\\\\"  # or your preferred model\\\\n```\\\\nAlternatively, you can use a `.env` file in your project root:\\\\n```env\\\\nANTHROPIC_API_KEY=your-anthropic-api-key\\\\nANTHROPIC_CHAT_MODEL_ID=claude-sonnet-4-5-20250929\\\\n```\\\\nYou can get an API key from the [Anthropic Console](https://console.anthropic.com/).\\\\n## Getting Started\\\\nImport the required classes from the Agent Framework:\\\\n```python\\\\nimport asyncio\\\\nfrom agent_framework.anthropic import AnthropicClient\\\\n```\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/agent-types/anthropic-agent#creating-an-anthropic-agent\\\"}, {\\\"title\\\": \\\"AIFoundryModel.Anthropic.ClaudeSonnet45 Field-Definition\\\", \\\"content\\\": \\\"# AIFoundryModel.Anthropic.ClaudeSonnet45 Field\\\\r\\\\n\\\\r\\\\n## Definition\\\\r\\\\n\\\\r\\\\n- Namespace:\\\\r\\\\n    - [Aspire.Hosting.Azure](https://learn.microsoft.com/en-us/dotnet/api/aspire.hosting.azure?view=dotnet-aspire-13.0)\\\\r\\\\n\\\\r\\\\n- Assembly:\\\\r\\\\n    - Aspire.Hosting.Azure.AIFoundry.dll\\\\r\\\\n\\\\r\\\\n- Package:\\\\r\\\\n    - Aspire.Hosting.Azure.AIFoundry v13.1.0-preview.1.25616.3\\\\r\\\\n\\\\r\\\\n- Source:\\\\r\\\\n    - [AIFoundryModel.Generated.cs](https://github.com/dotnet/aspire/blob/8a4db1775c3fbae1c602022b636299cb04971fde/src/Aspire.Hosting.Azure.AIFoundry/AIFoundryModel.Generated.cs)\\\\r\\\\n\\\\r\\\\nClaude Sonnet 4.5 is Anthropic's most capable model for complex agents and an industry leader for coding and computer use.\\\\r\\\\n\\\\r\\\\n```csharp\\\\r\\\\npublic static readonly Aspire.Hosting.Azure.AIFoundryModel ClaudeSonnet45;\\\\r\\\\n```\\\\r\\\\n\\\\r\\\\n#### Field Value\\\\r\\\\n\\\\r\\\\n[AIFoundryModel](https://learn.microsoft.com/en-us/dotnet/api/aspire.hosting.azure.aifoundrymodel?view=dotnet-aspire-13.0)\\\", \\\"contentUrl\\\": \\\"https://learn.microsoft.com/en-us/dotnet/api/aspire.hosting.azure.aifoundrymodel.anthropic.claudesonnet45?view=dotnet-aspire-13.0\\\"}]}\",\n",
      "      \"status\": \"completed\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"mcp_0bca83ff5eb7ed76006964a36910948193944b4a8454e3a21b\",\n",
      "      \"arguments\": \"{\\\"url\\\":\\\"https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-models/how-to/use-foundry-models-claude?view=foundry-classic\\\"}\",\n",
      "      \"name\": \"microsoft_docs_fetch\",\n",
      "      \"server_label\": \"Microsoft_Learn_MCP_Server\",\n",
      "      \"type\": \"mcp_call\",\n",
      "      \"approval_request_id\": null,\n",
      "      \"error\": null,\n",
      "      \"output\": \"# Deploy and use Claude models in Microsoft Foundry (preview)\\r\\n\\r\\nNote\\r\\n\\r\\nThis document refers to the [Microsoft Foundry (classic)](../../what-is-foundry?view=foundry-classic#microsoft-foundry-portals) portal.\\r\\n\\r\\nüîÑ [Switch to the Microsoft Foundry (new) documentation](?view=foundry&amp;preserve-view=true) if you're using the new portal.\\r\\n\\r\\nNote\\r\\n\\r\\nThis document refers to the [Microsoft Foundry (new)](../../what-is-foundry?view=foundry-classic#microsoft-foundry-portals) portal.\\r\\n\\r\\nThis article explains how to deploy and use the latest Claude models in Foundry, including Claude Opus 4.5, Claude Sonnet 4.5, Claude Haiku 4.5, and Claude Opus 4.1. Anthropic's flagship product is Claude, a frontier AI model useful for complex tasks such as coding, agents, financial analysis, research, and office tasks. Claude delivers exceptional performance while maintaining high safety standards.\\r\\n\\r\\nImportant\\r\\n\\r\\nTo use Claude models in Microsoft Foundry, you need a paid Azure subscription with a billing account in a [country or region](../../how-to/deploy-models-serverless-availability?view=foundry-classic#region-availability) where Anthropic offers the models for purchase. The following paid subscription types are currently restricted: Cloud Solution Providers (CSP), sponsored accounts with Azure credits, enterprise accounts in Singapore and South Korea, and Microsoft accounts.\\r\\n\\r\\nFor a list of common subscription-related errors, see [Common error messages and solutions](/en-us/marketplace/purchase-saas-offer-in-azure-portal#common-error-messages-and-solutions).\\r\\n\\r\\n## Available Claude models\\r\\n\\r\\nFoundry supports Claude Opus 4.5, Claude Sonnet 4.5, Claude Haiku 4.5, and Claude Opus 4.1 models through global standard deployment. These models have key capabilities that include:\\r\\n\\r\\n- **Extended thinking**: Extended thinking gives Claude enhanced reasoning capabilities for complex tasks.\\r\\n- **Image and text input**: Strong vision capabilities that enable the models to process images and return text outputs for analyzing and understanding charts, graphs, technical diagrams, reports, and other visual assets.\\r\\n- **Code generation**: Advanced thinking that includes code generation, analysis, and debugging for Claude Sonnet 4.5 and Claude Opus 4.1.\\r\\n\\r\\nFor more details about the model capabilities, see [capabilities of Claude models](../concepts/models-from-partners?view=foundry-classic#anthropic).\\r\\n\\r\\n#### Claude Opus 4.5 (preview)\\r\\n\\r\\nClaude Opus 4.5 is Anthropic's most intelligent model, and an industry leader across coding, agents, computer use, and enterprise workflows. With a 200K token context window and 64K max output, Opus 4.5 is ideal for production code, sophisticated agents, office tasks, financial analysis, cybersecurity, and computer use.\\r\\n\\r\\n#### Claude Sonnet 4.5 (preview)\\r\\n\\r\\nClaude Sonnet 4.5 is a highly capable model designed for building real-world agents and handling complex, long-horizon tasks. It offers a strong balance of speed and cost for high-volume use cases. Sonnet 4.5 also provides advanced accuracy for computer use, enabling developers to direct Claude to use computers the way people do.\\r\\n\\r\\n#### Claude Haiku 4.5 (preview)\\r\\n\\r\\nClaude Haiku 4.5 delivers near-frontier performance for a wide range of use cases. It stands out as one of the best coding and agent models, with the right speed and cost to power free products and scaled sub-agents.\\r\\n\\r\\n#### Claude Opus 4.1 (preview)\\r\\n\\r\\nClaude Opus 4.1 is an industry leader for coding. It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, significantly expanding what AI agents can solve.\\r\\n\\r\\n## Prerequisites\\r\\n\\r\\n- An Azure subscription with a valid payment method. If you don't have an Azure subscription, create a [paid Azure account](https://azure.microsoft.com/pricing/purchase-options/pay-as-you-go) to begin.\\r\\n- Access to Microsoft Foundry with appropriate permissions to create and manage resources.\\r\\n- A [Microsoft Foundry project](../../how-to/create-projects?view=foundry-classic) created in one of the supported regions: **East US2** and **Sweden Central**.\\r\\n- [Foundry Models from partners and community](../concepts/models-from-partners?view=foundry-classic) require access to **Azure Marketplace** to create subscriptions. Ensure you have the [permissions required to subscribe to model offerings](configure-marketplace?view=foundry-classic).\\r\\n\\r\\n## Deploy Claude models\\r\\n\\r\\nClaude models in Foundry are available for [global standard deployment](../concepts/deployment-types?view=foundry-classic#global-standard). To deploy a Claude model, follow the instructions in [Deploy Microsoft Foundry Models in the Foundry portal](deploy-foundry-models?view=foundry-classic).\\r\\n\\r\\nAfter deployment, you can use the [Foundry playground](../../concepts/concept-playgrounds?view=foundry-classic) to interactively test the model.\\r\\n\\r\\n## Work with Claude models\\r\\n\\r\\nOnce deployed, you have some options for interacting with Claude models to generate text responses:\\r\\n\\r\\n- Use the [Anthropic SDKs](https://docs.claude.com/en/api/client-sdks) and the following Claude APIs:\\r\\n\\r\\n    - [Messages API](https://docs.claude.com/en/api/messages) to send a structured list of input messages with text and/or image content, and the model generates the next message in the conversation.\\r\\n    - [Token Count API](https://docs.claude.com/en/api/messages-count-tokens) to count the number of tokens in a message.\\r\\n    - [Files API](https://docs.claude.com/en/api/files-create) to upload and manage files to use with the Claude API without having to re-upload content with each request.\\r\\n    - [Skills API](https://docs.claude.com/en/api/skills/create-skill) to create custom skills for Claude AI.\\r\\n\\r\\n### Use the Messages API to work with Claude models\\r\\n\\r\\nThe following examples show how to **use the Messages API** to send requests to Claude Sonnet 4.5, by using both Microsoft Entra ID authentication and API key authentication methods. To work with your deployed model, you need these items:\\r\\n\\r\\n- Your base URL, which is of the form `https://<resource name>.services.ai.azure.com/anthropic`.\\r\\n- Your target URI from your deployment details, which is of the form `https://<resource name>.services.ai.azure.com/anthropic/v1/messages`.\\r\\n- Microsoft Entra ID for keyless authentication or your deployment's API key for API authentication.\\r\\n- Deployment name you chose during deployment creation. This name can be different from the model ID.\\r\\n\\r\\n**Python**\\r\\n#### Use Microsoft Entra ID authentication\\r\\n\\r\\nFor Messages API endpoints, use your base URL with Microsoft Entra ID authentication.\\r\\n\\r\\n1. **Install the Azure Identity client library**: You need to install this library to use the `DefaultAzureCredential`. Authorization is easiest when you use `DefaultAzureCredential`, as it finds the best credential to use in its running environment.\\r\\n\\r\\n    ```bash\\r\\n    pip install azure.identity\\r\\n    ```\\r\\n\\r\\n    Set the values of the client ID, tenant ID, and client secret of the Microsoft Entra ID application as environment variables: `AZURE_CLIENT_ID`, `AZURE_TENANT_ID`, `AZURE_CLIENT_SECRET`.\\r\\n\\r\\n    ```bash\\r\\n    export AZURE_CLIENT_ID=\\\"<AZURE_CLIENT_ID>\\\"\\r\\n    export AZURE_TENANT_ID=\\\"<AZURE_TENANT_ID>\\\"\\r\\n    export AZURE_CLIENT_SECRET=\\\"<AZURE_CLIENT_SECRET>\\\"\\r\\n    ```\\r\\n2. **Install dependencies:** Install the Anthropic SDK by using pip (requires: Python &gt;=3.8).\\r\\n\\r\\n    ```bash\\r\\n    pip install -U \\\"anthropic\\\"\\r\\n    ```\\r\\n3. **Run a basic code sample:** This sample completes the following tasks:\\r\\n\\r\\n    1. Creates a client with the Anthropic SDK, using Microsoft Entra ID authentication.\\r\\n    2. Makes a basic call to the Messages API. The call is synchronous.\\r\\n\\r\\n    ```python\\r\\n    from anthropic import AnthropicFoundry\\r\\n    from azure.identity import DefaultAzureCredential, get_bearer_token_provider\\r\\n    \\r\\n    baseURL = \\\"https://<resource-name>.services.ai.azure.com/anthropic\\\" # Your base URL. Replace <resource-name> with your resource name\\r\\n    deploymentName = \\\"claude-sonnet-4-5\\\" # Replace with your deployment name\\r\\n    \\r\\n    # Create token provider for Entra ID authentication\\r\\n    tokenProvider = get_bearer_token_provider(\\r\\n        DefaultAzureCredential(), \\\"https://cognitiveservices.azure.com/.default\\\"\\r\\n    )\\r\\n    \\r\\n    # Create client with Entra ID authentication\\r\\n    client = AnthropicFoundry(\\r\\n        azure_ad_token_provider=tokenProvider,\\r\\n        base_url=baseURL\\r\\n    )\\r\\n    \\r\\n    # Send request\\r\\n    message = client.messages.create(\\r\\n        model=deployment_name,\\r\\n        messages=[\\r\\n            {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What is the capital/major city of France?\\\"}\\r\\n        ],\\r\\n        max_tokens=1024,\\r\\n    )\\r\\n    \\r\\n    print(message.content)\\r\\n    ```\\r\\n\\r\\n#### Use API key authentication\\r\\n\\r\\nFor Messages API endpoints, use your base URL and API key to authenticate against the service.\\r\\n\\r\\n1. **Install dependencies:** Install the Anthropic SDK by using pip (requires: Python &gt;=3.8):\\r\\n\\r\\n    ```bash\\r\\n    pip install -U \\\"anthropic\\\"\\r\\n    ```\\r\\n2. **Run a basic code sample:** This sample completes the following tasks:\\r\\n\\r\\n    1. Creates a client with the Anthropic SDK by passing your API key to the SDK's configuration. This authentication method lets you interact seamlessly with the service.\\r\\n    2. Makes a basic call to the Messages API. The call is synchronous.\\r\\n\\r\\n    ```python\\r\\n    from anthropic import AnthropicFoundry\\r\\n    \\r\\n    baseURL = \\\"https://<resource-name>.services.ai.azure.com/anthropic\\\" # Your base URL. Replace <resource-name> with your resource name\\r\\n    deploymentName = \\\"claude-sonnet-4-5\\\" # Replace with your deployment name\\r\\n    apiKey = \\\"YOUR_API_KEY\\\" # Replace YOUR_API_KEY with your API key\\r\\n    \\r\\n    # Create client with API key authentication\\r\\n    client = AnthropicFoundry(\\r\\n        api_key=apiKey,\\r\\n        base_url=baseURL\\r\\n    )\\r\\n    \\r\\n    # Send request\\r\\n    message = client.messages.create(\\r\\n        model=deploymentName,\\r\\n        messages=[\\r\\n            {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What is the capital/major city of France?\\\"}\\r\\n        ],\\r\\n        max_tokens=1024,\\r\\n    )\\r\\n    \\r\\n    print(message.content)\\r\\n    ```\\r\\n\\r\\n**JavaScript**\\r\\n#### Use Microsoft Entra ID authentication\\r\\n\\r\\nFor Messages API endpoints, use your base URL with Microsoft Entra ID authentication.\\r\\n\\r\\n1. **Install the Azure Identity client library**: Install the `@azure/identity` package to use the `DefaultAzureCredential`. Authorization is easiest when you use `DefaultAzureCredential`, as it finds the best credential to use in its running environment.\\r\\n\\r\\n    ```bash\\r\\n    npm install @azure/identity\\r\\n    ```\\r\\n\\r\\n    Set the values of the client ID, tenant ID, and client secret of the Microsoft Entra ID application as environment variables: `AZURE_CLIENT_ID`, `AZURE_TENANT_ID`, `AZURE_CLIENT_SECRET`.\\r\\n\\r\\n    ```bash\\r\\n    export AZURE_CLIENT_ID=\\\"<AZURE_CLIENT_ID>\\\"\\r\\n    export AZURE_TENANT_ID=\\\"<AZURE_TENANT_ID>\\\"\\r\\n    export AZURE_CLIENT_SECRET=\\\"<AZURE_CLIENT_SECRET>\\\"\\r\\n    ```\\r\\n2. **Install dependencies**\\r\\n\\r\\n    1. Install [Node.js](https://nodejs.org/) 20 LTS or later ([non-EOL](https://endoflife.date/nodejs)) versions.\\r\\n    2. Copy the following lines of text and save them as a file `package.json` inside your folder.\\r\\n\\r\\n        ```json\\r\\n        {\\r\\n          \\\"type\\\": \\\"module\\\",\\r\\n          \\\"dependencies\\\": {\\r\\n            \\\"@anthropic-ai/sdk\\\": \\\"latest\\\",\\r\\n            \\\"@azure/identity\\\": \\\"latest\\\"\\r\\n          }\\r\\n        }\\r\\n        ```\\r\\n\\r\\n        Note\\r\\n\\r\\n        @azure/core-sse is only needed when you stream the response.\\r\\n    3. Open a terminal window in this folder and run `npm install`.\\r\\n    4. For each of the code snippets that follow, copy the content into a file `sample.js` and run with `node sample.js`.\\r\\n3. **Run a basic code sample.** This sample completes the following tasks:\\r\\n\\r\\n    1. Creates a client with the Anthropic SDK, using Microsoft Entra ID authentication.\\r\\n    2. Makes a basic call to the Messages API. The call is synchronous.\\r\\n\\r\\n    ```javascript\\r\\n    import AnthropicFoundry from '@anthropic-ai/foundry-sdk';\\r\\n    import { getBearerTokenProvider, DefaultAzureCredential } from \\\"@azure/identity\\\";\\r\\n    \\r\\n    const baseURL = \\\"https://<resource-name>.services.ai.azure.com/anthropic\\\"; // Your base URL. Replace <resource-name> with your resource name\\r\\n    const deploymentName = \\\"claude-sonnet-4-5\\\" // Replace with your deployment name\\r\\n    \\r\\n    // Create token provider for Entra ID authentication\\r\\n    const tokenProvider = getBearerTokenProvider(\\r\\n        new DefaultAzureCredential(),\\r\\n        'https://cognitiveservices.azure.com/.default');\\r\\n    \\r\\n    // Create client with Entra ID authentication\\r\\n    const client = new AnthropicFoundry({\\r\\n        azureADTokenProvider: tokenProvider,\\r\\n        baseURL: baseURL,\\r\\n        apiVersion: \\\"2023-06-01\\\"\\r\\n    });\\r\\n    \\r\\n    // Send request\\r\\n    const message = await client.messages.create({\\r\\n        model: deploymentName,\\r\\n        messages: [{ role: \\\"user\\\", content: \\\"What is the capital/major city of France?\\\" }],\\r\\n        max_tokens: 1024,\\r\\n    });\\r\\n    console.log(message);\\r\\n    ```\\r\\n\\r\\n#### Use API key authentication\\r\\n\\r\\nFor Messages API endpoints, use your base URL and API key to authenticate against the service.\\r\\n\\r\\n1. **Install dependencies**\\r\\n\\r\\n    1. Install [Node.js](https://nodejs.org/) 20 LTS or later ([non-EOL](https://endoflife.date/nodejs)) versions.\\r\\n    2. Copy the following lines of text and save them as a file `package.json` inside your folder.\\r\\n\\r\\n        ```json\\r\\n        {\\r\\n          \\\"type\\\": \\\"module\\\",\\r\\n          \\\"dependencies\\\": {\\r\\n            \\\"@anthropic-ai/sdk\\\": \\\"latest\\\"\\r\\n          }\\r\\n        }\\r\\n        ```\\r\\n\\r\\n        Note\\r\\n\\r\\n        @azure/core-sse is only needed when you stream the response.\\r\\n    3. Open a terminal window in this folder and run `npm install`.\\r\\n    4. For each of the code snippets that follow, copy the content into a file `sample.js` and run with `node sample.js`.\\r\\n2. **Run a basic code sample.** This sample completes the following tasks:\\r\\n\\r\\n    1. Creates a client with the Anthropic SDK by passing your API key to the SDK's configuration. This authentication method lets you interact seamlessly with the service.\\r\\n    2. Makes a basic call to the Messages API. The call is synchronous.\\r\\n\\r\\n    ```javascript\\r\\n    import AnthropicFoundry from '@anthropic-ai/foundry-sdk';\\r\\n    \\r\\n    const baseURL = \\\"https://<resource-name>.services.ai.azure.com/anthropic\\\"; // Your base URL. Replace <resource-name> with your resource name\\r\\n    const deploymentName = \\\"claude-sonnet-4-5\\\" // Replace with your deployment name\\r\\n    const apiKey = \\\"<your-api-key>\\\"; // Your API key\\r\\n    \\r\\n    // Create client with API key\\r\\n    const client = new AnthropicFoundry({\\r\\n        apiKey: apiKey,\\r\\n        baseURL: baseURL,\\r\\n        apiVersion: \\\"2023-06-01\\\"\\r\\n    });\\r\\n    \\r\\n    // Send request\\r\\n    const message = await client.messages.create({\\r\\n        model: deploymentName,\\r\\n        messages: [{ role: \\\"user\\\", content: \\\"What is the capital/major city of France?\\\" }],\\r\\n        max_tokens: 1024,\\r\\n    });\\r\\n    console.log(message);\\r\\n    ```\\r\\n\\r\\nFor a list of supported runtimes, see [Requirements to use Anthropic TypeScript API Library](https://github.com/anthropics/anthropic-sdk-typescript#requirements).\\r\\n\\r\\n**REST API**\\r\\n#### Use Microsoft Entra ID authentication\\r\\n\\r\\nFor Messages API endpoints, use the deployed model's endpoint URI `https://<resource-name>.services.ai.azure.com/anthropic/v1/messages` with Microsoft Entra ID authentication.\\r\\n\\r\\nIf you configure the resource with Microsoft Entra ID support, pass your token in the Authorization header with the format `Bearer $AZURE_AUTH_TOKEN`. Use scope `https://cognitiveservices.azure.com/.default`. Using Microsoft Entra ID might require additional configuration in your resource to grant access. For more information, see [configure authentication with Microsoft Entra ID](/en-us/azure/ai-foundry/foundry-models/how-to/configure-entra-id?tabs=rest#use-microsoft-entra-id-in-your-code).\\r\\n\\r\\n1. Export your Microsoft Entra ID token to an environment variable:\\r\\n\\r\\n    If you're using bash:\\r\\n\\r\\n    ```bash\\r\\n    export AZURE_AUTH_TOKEN=\\\"<your-entra-id-key>\\\"\\r\\n    ```\\r\\n\\r\\n    If you're in PowerShell:\\r\\n\\r\\n    ```powershell\\r\\n    $Env:AZURE_AUTH_TOKEN = \\\"<your-entra-id-key>\\\"\\r\\n    ```\\r\\n\\r\\n    If you're using Windows command prompt:\\r\\n\\r\\n    ```\\r\\n    set AZURE_AUTH_TOKEN = <your-entra-id-key>\\r\\n    ```\\r\\n2. Run the following cURL command. For cURL, use your deployment's target URI `https://<resource-name>.services.ai.azure.com/anthropic/v1/messages`.\\r\\n\\r\\n    ```sh\\r\\n    curl -X POST https://<resource-name>.services.ai.azure.com/anthropic/v1/messages \\\\\\r\\n      -H \\\"Content-Type: application/json\\\" \\\\\\r\\n      -H \\\"Authorization: Bearer $AZURE_AUTH_TOKEN\\\" \\\\\\r\\n      -H \\\"anthropic-version: 2023-06-01\\\" \\\\\\r\\n      -d '{\\r\\n        \\\"messages\\\": [\\r\\n          {\\r\\n            \\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a helpful assistant.\\\"\\r\\n          },\\r\\n          {\\r\\n            \\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What are 3 things to visit in Seattle?\\\"\\r\\n          }\\r\\n        ],\\r\\n        \\\"max_tokens\\\": 1000,\\r\\n        \\\"temperature\\\": 0.7,\\r\\n        \\\"model\\\": \\\"claude-sonnet-4-5\\\"\\r\\n        }'\\r\\n    ```\\r\\n\\r\\n#### Use API key authentication\\r\\n\\r\\nFor Messages API endpoints, use the deployed model's endpoint URI `https://<resource-name>.services.ai.azure.com/anthropic/v1/messages` and API key to authenticate against the service.\\r\\n\\r\\n1. Export your API key to an environment variable:\\r\\n\\r\\n    If you're using bash:\\r\\n\\r\\n    ```bash\\r\\n    export AZURE_API_KEY=\\\"<your-api-key>\\\"\\r\\n    ```\\r\\n\\r\\n    If you're in PowerShell:\\r\\n\\r\\n    ```powershell\\r\\n    $Env:AZURE_API_KEY = \\\"<your-api-key>\\\"\\r\\n    ```\\r\\n\\r\\n    If you're using Windows command prompt:\\r\\n\\r\\n    ```\\r\\n    set AZURE_API_KEY = <your-api-key>\\r\\n    ```\\r\\n2. Run the following cURL command:\\r\\n\\r\\n    ```sh\\r\\n    curl -X POST https://<resource-name>.services.ai.azure.com/anthropic/v1/messages \\\\\\r\\n      -H \\\"Content-Type: application/json\\\" \\\\\\r\\n      -H \\\"x-api-key: $AZURE_API_KEY\\\" \\\\\\r\\n      -H \\\"anthropic-version: 2023-06-01\\\" \\\\\\r\\n      -d '{\\r\\n        \\\"messages\\\": [\\r\\n          {\\r\\n            \\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a helpful assistant.\\\"\\r\\n          },\\r\\n          {\\r\\n            \\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What are 3 things to visit in Seattle?\\\"\\r\\n          }\\r\\n        ],\\r\\n        \\\"max_tokens\\\": 1000,\\r\\n        \\\"temperature\\\": 0.7,\\r\\n        \\\"model\\\": \\\"claude-sonnet-4-5\\\"\\r\\n        }'\\r\\n    ```\\r\\n\\r\\n## Agent support\\r\\n\\r\\n- [Microsoft Agent Framework](/en-us/agent-framework/user-guide/agents/agent-types/anthropic-agent) supports creating agents that use Claude models.\\r\\n- You can build custom AI agents with the [Claude Agent SDK](https://docs.claude.com/en/docs/agent-sdk/overview).\\r\\n\\r\\n## Claude advanced features and capabilities\\r\\n\\r\\nClaude in Foundry Models supports advanced features and capabilities. **Core capabilities** enhance Claude's fundamental abilities for processing, analyzing, and generating content across various formats and use cases. **Tools** enable Claude to interact with external systems, execute code, and perform automated tasks through various tool interfaces.\\r\\n\\r\\nSome of the **Core capabilities** that Foundry supports are:\\r\\n\\r\\n- **1 million token context window:** An extended context window.\\r\\n- **Agent skills:** Extend Claude's capabilities with Skills.\\r\\n- **Citations:** Ground Claude's responses in source documents.\\r\\n- **Context editing:** Automatically manage conversation context with configurable strategies.\\r\\n- **Extended thinking:** Enhanced reasoning capabilities for complex tasks.\\r\\n- **PDF support:** Process and analyze text and visual content from PDF documents.\\r\\n- **Prompt caching:** Provide Claude with more background knowledge and example outputs to reduce costs and latency.\\r\\n\\r\\nSome of the **Tools** that Foundry supports are:\\r\\n\\r\\n- **MCP connector:** Connect to remote MCP servers directly from the Messages API without a separate MCP client.\\r\\n- **Memory:** Store and retrieve information across conversations. Build knowledge bases over time, maintain project context, and learn from past interactions.\\r\\n- **Web fetch:** Retrieve full content from specified web pages and PDF documents for in-depth analysis.\\r\\n\\r\\nFor a full list of the supported capabilities and tools, see [Claude's features overview](https://docs.claude.com/en/docs/build-with-claude/overview).\\r\\n\\r\\n## API quotas and limits\\r\\n\\r\\nImportant\\r\\n\\r\\nAt this time, only Enterprise and MCA-E subscriptions are eligible for Claude model usage in Foundry.\\r\\n\\r\\nClaude models in Foundry have the following rate limits, measured in Tokens Per Minute (TPM) and Requests Per Minute (RPM):\\r\\n\\r\\n| Model | Deployment Type | Default RPM | Default TPM | Enterprise and MCA-E RPM | Enterprise and MCA-E TPM |\\r\\n| --- | --- | --- | --- | --- | --- |\\r\\n| claude-haiku-4-5 | [Global Standard](../concepts/deployment-types?view=foundry-classic#global-standard) | 0 | 0 | 4,000 | 4,000,000 |\\r\\n| claude-opus-4-1 | Global Standard | 0 | 0 | 2,000 | 2,000,000 |\\r\\n| claude-sonnet-4-5 | Global Standard | 0 | 0 | 4,000 | 2,000,000 |\\r\\n| claude-opus-4-5 | Global Standard | 0 | 0 | 2,000 | 2,000,000 |\\r\\n\\r\\nTo increase your quota beyond the default limits, submit a request through the [quota increase request form](https://aka.ms/oai/stuquotarequest).\\r\\n\\r\\n### Rate limit best practices\\r\\n\\r\\nTo optimize your usage and avoid rate limiting:\\r\\n\\r\\n- **Implement retry logic**: Handle 429 responses with exponential backoff\\r\\n- **Batch requests**: Combine multiple prompts when possible\\r\\n- **Monitor usage**: Track your token consumption and request patterns\\r\\n- **Use appropriate models**: Choose the right Claude model for your use case\\r\\n\\r\\n## Responsible AI considerations\\r\\n\\r\\nWhen using Claude models in Foundry, consider these responsible AI practices:\\r\\n\\r\\n- Configure AI content safety during model inference, as Foundry doesn't provide built-in content filtering for Claude models at deployment time. To learn how to create and use content filters, see [Configure content filtering for Foundry Models](configure-content-filters?view=foundry-classic).\\r\\n- Ensure your applications comply with [Anthropic's Acceptable Use Policy](https://www.anthropic.com/legal/aup). Also, see details of safety evaluations for [Claude Opus 4.5](http://www.anthropic.com/claude-opus-4-5-system-card), [Claude Haiku 4.5](https://assets.anthropic.com/m/99128ddd009bdcb/Claude-Haiku-4-5-System-Card.pdf), [Claude Opus 4.1](https://assets.anthropic.com/m/4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf), and [Claude Sonnet 4.5](https://assets.anthropic.com/m/12f214efcc2f457a/original/Claude-Sonnet-4-5-System-Card.pdf).\\r\\n\\r\\n- Configure AI content safety during model inference, as Foundry doesn't provide built-in content filtering for Claude models at deployment time.\\r\\n- Ensure your applications comply with [Anthropic's Acceptable Use Policy](https://www.anthropic.com/legal/aup). Also, see details of safety evaluations for [Claude Opus 4.5](http://www.anthropic.com/claude-opus-4-5-system-card), [Claude Haiku 4.5](https://assets.anthropic.com/m/99128ddd009bdcb/Claude-Haiku-4-5-System-Card.pdf), [Claude Opus 4.1](https://assets.anthropic.com/m/4c024b86c698d3d4/original/Claude-4-1-System-Card.pdf), and [Claude Sonnet 4.5](https://assets.anthropic.com/m/12f214efcc2f457a/original/Claude-Sonnet-4-5-System-Card.pdf).\\r\\n\\r\\n## Best practices\\r\\n\\r\\nFollow these best practices when working with Claude models in Foundry:\\r\\n\\r\\n#### Model selection\\r\\n\\r\\nChoose the appropriate Claude model based on your specific requirements:\\r\\n\\r\\n- **Claude Opus 4.5**: For best performance across coding, agents, computer use, and enterprise workflows\\r\\n- **Claude Sonnet 4.5**: For balanced performance and capabilities, production workflows\\r\\n- **Claude Haiku 4.5**: For speed and cost optimization, high-volume processing\\r\\n- **Claude Opus 4.1**: For complex reasoning and enterprise applications\\r\\n\\r\\n#### Prompt engineering\\r\\n\\r\\n- **Clear instructions**: Provide specific and detailed prompts\\r\\n- **Context management**: Effectively use the available context window\\r\\n- **Role definitions**: Use system messages to define the assistant's role and behavior\\r\\n- **Structured prompts**: Use consistent formatting for better results\\r\\n\\r\\n#### Cost optimization\\r\\n\\r\\n- **Token management**: Monitor and optimize token usage\\r\\n- **Model selection**: Use the most cost-effective model for your use case\\r\\n- **Caching**: Implement [explicit prompt caching](https://docs.claude.com/en/docs/build-with-claude/prompt-caching#continuing-a-multi-turn-conversation) where appropriate\\r\\n- **Request batching**: Combine multiple requests when possible\",\n",
      "      \"status\": \"completed\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_0bca83ff5eb7ed76006964a369e8f08193b8f7375b10acde6a\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"### Microsoft Foundry„Åß„Éõ„Çπ„Éà„Åï„Çå„ÇãAnthropic Claude Haiku 4.5„Å´„Å§„ÅÑ„Å¶\\n\\n**Claude Haiku 4.5**„ÅØ„ÄÅAnthropic„ÅåÈñãÁô∫„Åó„ÅüAI„É¢„Éá„É´„ÅÆ‰∏Ä„Å§„Åß„ÄÅMicrosoft Foundry„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†‰∏ä„ÅßÂà©Áî®ÂèØËÉΩ„Åß„Åô„ÄÇ‰ª•‰∏ã„Å´„Åù„ÅÆ‰∏ªË¶Å„Å™ÁâπÂæ¥„ÇÑÊ©üËÉΩ„ÇíË©≥Ëø∞„Åó„Åæ„Åô„ÄÇ\\n\\n#### 1. „É¢„Éá„É´„ÅÆÁâπÂæ¥\\n- **ÊÄßËÉΩ**: Claude Haiku 4.5„ÅØ„ÄÅÂπÖÂ∫É„ÅÑ„É¶„Éº„Çπ„Ç±„Éº„Çπ„Å´ÂØæÂøú„Åô„ÇãÈ´òÊÄßËÉΩ„Å™„É¢„Éá„É´„Åß„ÅÇ„Çä„ÄÅÁâπ„Å´„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„ÇÑ„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÊßãÁØâ„Å´ÂÑ™„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n- **ÈÄüÂ∫¶„Å®„Ç≥„Çπ„Éà**: È´òÈÄüÂá¶ÁêÜ„ÅåÂèØËÉΩ„Åß„ÄÅ„Ç≥„Çπ„ÉàÂäπÁéá„ÇÇËâØ„ÅÑ„Åü„ÇÅ„ÄÅ„Çπ„Ç±„Éº„É´„ÅÆÂ§ß„Åç„ÅÑ„Çµ„Éñ„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÈÅãÁî®„Å´ÈÅ©„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\\n- **ÂÖ•ÂäõÂΩ¢Âºè**: „ÉÜ„Ç≠„Çπ„Éà„Åä„Çà„Å≥ÁîªÂÉè„ÅÆÂÖ•Âäõ„ÇíÂèó„Åë‰ªò„Åë„ÄÅÊúÄÂ§ß64,000„Éà„Éº„ÇØ„É≥„ÅÆÂá∫Âäõ„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅ„Éá„Éº„ÇøÂàÜÊûê„ÇÑË§áÈõë„Å™Ë¶ñË¶öÊÉÖÂ†±„ÅÆÂá¶ÁêÜ„ÅåÂÆπÊòì„Å´„Å™„Çä„Åæ„Åô„ÄÇ\\n\\n#### 2. ‰∏ª„Å™Ê©üËÉΩ\\n- **Êã°ÂºµÊÄùËÄÉ**: Ë§áÈõë„Å™„Çø„Çπ„ÇØ„Å´ÂØæ„Åô„ÇãÈ´òÂ∫¶„Å™Êé®Ë´ñËÉΩÂäõ„ÇíÂÇô„Åà„Å¶„Åä„Çä„ÄÅÊßò„ÄÖ„Å™„Éì„Ç∏„Éç„Çπ„Éã„Éº„Ç∫„Å´Âøú„Åò„ÅüËß£Ê±∫Á≠ñ„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇ\\n- **ÁîªÂÉèÂá¶ÁêÜËÉΩÂäõ**: ÁîªÂÉè„Å®„ÉÜ„Ç≠„Çπ„Éà„ÅÆ‰∏°Êñπ„ÇíÂá¶ÁêÜ„Åó„ÄÅÂõ≥Ë°®„ÇÑÊäÄË°ìÂõ≥Èù¢„ÅÆÁêÜËß£„ÇíÊîØÊè¥„Åó„Åæ„Åô„ÄÇ\\n- **„Ç≥„Éº„ÉâÁîüÊàê**: „Ç≥„Éº„Éâ„ÅÆÁîüÊàê„ÄÅÂàÜÊûê„ÄÅ„Éá„Éê„ÉÉ„Ç∞Ê©üËÉΩ„ÅåÂº∑Âåñ„Åï„Çå„Å¶„Åä„Çä„ÄÅÈñãÁô∫ËÄÖ„Å´„Å®„Å£„Å¶ÈùûÂ∏∏„Å´‰æøÂà©„Åß„Åô„ÄÇ\\n\\n#### 3. ‰ΩøÁî®ÊñπÊ≥ï\\n- **„Éá„Éó„É≠„Ç§**: Microsoft Foundry„ÇíÈÄö„Åò„Å¶„ÄÅClaude Haiku 4.5„Çí„Éá„Éó„É≠„Ç§„Åô„Çã„Å´„ÅØ„ÄÅAzure„ÅÆÊúâÊñô„Çµ„Éñ„Çπ„ÇØ„É™„Éó„Ç∑„Éß„É≥„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅ„É¢„Éá„É´„Çí‰ΩøÁî®„Åô„Çã„Åü„ÇÅ„ÅÆÈÅ©Âàá„Å™Ê®©Èôê„Å®„É™„ÇΩ„Éº„Çπ„ÅåÁ¢∫‰øù„Åï„Çå„Åæ„Åô„ÄÇ\\n- **API„Å®„ÅÆÈÄ£Êê∫**: ‰ΩøÁî®ËÄÖ„ÅØAnthropic„ÅÆSDK„ÇÑAPI„ÇíÂà©Áî®„Åó„Å¶„ÄÅ„É¢„Éá„É´„Å´„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÈÄÅ‰ø°„Åó„Åü„Çä„ÄÅÂøúÁ≠î„ÇíÂèó„ÅëÂèñ„Å£„Åü„Çä„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ\\n\\n#### 4. „Ç≥„Çπ„Éà„Å®Âà∂Èôê\\n- **„Éà„Éº„ÇØ„É≥ÁÆ°ÁêÜ**: „É¢„Éá„É´‰ΩøÁî®„Å´„ÅÇ„Åü„Çä„ÄÅ„Éà„Éº„ÇØ„É≥„ÅÆÊ∂àË≤ª„Çí„É¢„Éã„Çø„É™„É≥„Ç∞„Åó„ÄÅÂäπÁéáÁöÑ„Å™„É™„ÇΩ„Éº„Çπ‰ΩøÁî®„ÇíÂøÉ„Åå„Åë„Çã„Åì„Å®„ÅåÊé®Â•®„Åï„Çå„Åæ„Åô„ÄÇ\\n- **„É¨„Éº„ÉàÂà∂Èôê**: Claude Haiku 4.5„ÅØ„ÄÅ„Ç®„É≥„Çø„Éº„Éó„É©„Ç§„Ç∫„Åä„Çà„Å≥MCA-E„Çµ„Éñ„Çπ„ÇØ„É™„Éó„Ç∑„Éß„É≥Áî®„Å´Ë®≠ÂÆö„Åï„Çå„ÅüÁâπÂÆö„ÅÆ„Éà„Éº„ÇØ„É≥„Åä„Çà„Å≥„É™„ÇØ„Ç®„Çπ„Éà„ÅÆÂà∂Èôê„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\\n\\n#### 5. ÂÄ´ÁêÜÁöÑ„Å™AI„ÅÆËÄÉÊÖÆ\\n- ‰ΩøÁî®ÊôÇ„Å´„ÅØ„ÄÅAI„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÅÆÂÆâÂÖ®ÊÄß„ÇíÊßãÊàê„Åó„ÄÅAnthropic„ÅÆÂà©Áî®Ë¶èÁ¥Ñ„Å´Âæì„ÅÜ„Åì„Å®„ÅåÊ±Ç„ÇÅ„Çâ„Çå„Åæ„Åô„ÄÇÁâπ„Å´„ÄÅ„É¢„Éá„É´„ÅÆÊé®Ë´ñÊôÇ„Å´„Ç≥„É≥„ÉÜ„É≥„ÉÑ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„ÇíË®≠ÂÆö„Åô„Çã„Åì„Å®„ÅåÈáçË¶Å„Åß„Åô„ÄÇ\\n\\n### ÁµêË´ñ\\nClaude Haiku 4.5„ÅØ„ÄÅMicrosoft Foundry„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†‰∏ä„Åß„ÅÆÈ´òÂ∫¶„Å™AIÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„ÄÅ„Éì„Ç∏„Éç„Çπ„Éó„É≠„Çª„Çπ„ÅÆÊúÄÈÅ©Âåñ„ÇÑÂäπÁéáÂåñ„Å´ÂØÑ‰∏é„Åô„Çã„Åì„Å®„ÅåÊúüÂæÖ„Åï„Çå„Åæ„Åô„ÄÇÈñãÁô∫ËÄÖ„ÇÑ‰ºÅÊ•≠„ÅØ„ÄÅ„Åì„ÅÆ„É¢„Éá„É´„ÇíÊ¥ªÁî®„Åô„Çã„Åì„Å®„Åß„ÄÅË§áÈõë„Å™„Çø„Çπ„ÇØ„ÇíÂäπÊûúÁöÑ„Å´Âá¶ÁêÜ„Åó„ÄÅÁ´∂‰∫âÂäõ„ÇíÈ´ò„ÇÅ„Çã„Åì„Å®„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 0.8,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"server_label\": \"Microsoft_Learn_MCP_Server\",\n",
      "      \"type\": \"mcp\",\n",
      "      \"allowed_tools\": null,\n",
      "      \"authorization\": null,\n",
      "      \"connector_id\": null,\n",
      "      \"headers\": null,\n",
      "      \"require_approval\": \"never\",\n",
      "      \"server_description\": \"Stop AI Hallucinations. Give your AI assistant (Claude, Cursor, Copilot, Codex, ...) direct access to the latest official Microsoft documentation.\",\n",
      "      \"server_url\": \"https://learn.microsoft.com/api/mcp\"\n",
      "    }\n",
      "  ],\n",
      "  \"top_p\": 0.95,\n",
      "  \"background\": false,\n",
      "  \"completed_at\": null,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": 1000,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"prompt_cache_retention\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 11544,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 887,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 12431\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n",
      "----------------------------------------------------------------\n",
      "### Microsoft Foundry„Åß„Éõ„Çπ„Éà„Åï„Çå„ÇãAnthropic Claude Haiku 4.5„Å´„Å§„ÅÑ„Å¶\n",
      "\n",
      "**Claude Haiku 4.5**„ÅØ„ÄÅAnthropic„ÅåÈñãÁô∫„Åó„ÅüAI„É¢„Éá„É´„ÅÆ‰∏Ä„Å§„Åß„ÄÅMicrosoft Foundry„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†‰∏ä„ÅßÂà©Áî®ÂèØËÉΩ„Åß„Åô„ÄÇ‰ª•‰∏ã„Å´„Åù„ÅÆ‰∏ªË¶Å„Å™ÁâπÂæ¥„ÇÑÊ©üËÉΩ„ÇíË©≥Ëø∞„Åó„Åæ„Åô„ÄÇ\n",
      "\n",
      "#### 1. „É¢„Éá„É´„ÅÆÁâπÂæ¥\n",
      "- **ÊÄßËÉΩ**: Claude Haiku 4.5„ÅØ„ÄÅÂπÖÂ∫É„ÅÑ„É¶„Éº„Çπ„Ç±„Éº„Çπ„Å´ÂØæÂøú„Åô„ÇãÈ´òÊÄßËÉΩ„Å™„É¢„Éá„É´„Åß„ÅÇ„Çä„ÄÅÁâπ„Å´„Ç≥„Éº„Éá„Ç£„É≥„Ç∞„ÇÑ„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÊßãÁØâ„Å´ÂÑ™„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n",
      "- **ÈÄüÂ∫¶„Å®„Ç≥„Çπ„Éà**: È´òÈÄüÂá¶ÁêÜ„ÅåÂèØËÉΩ„Åß„ÄÅ„Ç≥„Çπ„ÉàÂäπÁéá„ÇÇËâØ„ÅÑ„Åü„ÇÅ„ÄÅ„Çπ„Ç±„Éº„É´„ÅÆÂ§ß„Åç„ÅÑ„Çµ„Éñ„Ç®„Éº„Ç∏„Çß„É≥„Éà„ÅÆÈÅãÁî®„Å´ÈÅ©„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n",
      "- **ÂÖ•ÂäõÂΩ¢Âºè**: „ÉÜ„Ç≠„Çπ„Éà„Åä„Çà„Å≥ÁîªÂÉè„ÅÆÂÖ•Âäõ„ÇíÂèó„Åë‰ªò„Åë„ÄÅÊúÄÂ§ß64,000„Éà„Éº„ÇØ„É≥„ÅÆÂá∫Âäõ„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅ„Éá„Éº„ÇøÂàÜÊûê„ÇÑË§áÈõë„Å™Ë¶ñË¶öÊÉÖÂ†±„ÅÆÂá¶ÁêÜ„ÅåÂÆπÊòì„Å´„Å™„Çä„Åæ„Åô„ÄÇ\n",
      "\n",
      "#### 2. ‰∏ª„Å™Ê©üËÉΩ\n",
      "- **Êã°ÂºµÊÄùËÄÉ**: Ë§áÈõë„Å™„Çø„Çπ„ÇØ„Å´ÂØæ„Åô„ÇãÈ´òÂ∫¶„Å™Êé®Ë´ñËÉΩÂäõ„ÇíÂÇô„Åà„Å¶„Åä„Çä„ÄÅÊßò„ÄÖ„Å™„Éì„Ç∏„Éç„Çπ„Éã„Éº„Ç∫„Å´Âøú„Åò„ÅüËß£Ê±∫Á≠ñ„ÇíÊèê‰æõ„Åó„Åæ„Åô„ÄÇ\n",
      "- **ÁîªÂÉèÂá¶ÁêÜËÉΩÂäõ**: ÁîªÂÉè„Å®„ÉÜ„Ç≠„Çπ„Éà„ÅÆ‰∏°Êñπ„ÇíÂá¶ÁêÜ„Åó„ÄÅÂõ≥Ë°®„ÇÑÊäÄË°ìÂõ≥Èù¢„ÅÆÁêÜËß£„ÇíÊîØÊè¥„Åó„Åæ„Åô„ÄÇ\n",
      "- **„Ç≥„Éº„ÉâÁîüÊàê**: „Ç≥„Éº„Éâ„ÅÆÁîüÊàê„ÄÅÂàÜÊûê„ÄÅ„Éá„Éê„ÉÉ„Ç∞Ê©üËÉΩ„ÅåÂº∑Âåñ„Åï„Çå„Å¶„Åä„Çä„ÄÅÈñãÁô∫ËÄÖ„Å´„Å®„Å£„Å¶ÈùûÂ∏∏„Å´‰æøÂà©„Åß„Åô„ÄÇ\n",
      "\n",
      "#### 3. ‰ΩøÁî®ÊñπÊ≥ï\n",
      "- **„Éá„Éó„É≠„Ç§**: Microsoft Foundry„ÇíÈÄö„Åò„Å¶„ÄÅClaude Haiku 4.5„Çí„Éá„Éó„É≠„Ç§„Åô„Çã„Å´„ÅØ„ÄÅAzure„ÅÆÊúâÊñô„Çµ„Éñ„Çπ„ÇØ„É™„Éó„Ç∑„Éß„É≥„ÅåÂøÖË¶Å„Åß„Åô„ÄÇ„Åì„Çå„Å´„Çà„Çä„ÄÅ„É¢„Éá„É´„Çí‰ΩøÁî®„Åô„Çã„Åü„ÇÅ„ÅÆÈÅ©Âàá„Å™Ê®©Èôê„Å®„É™„ÇΩ„Éº„Çπ„ÅåÁ¢∫‰øù„Åï„Çå„Åæ„Åô„ÄÇ\n",
      "- **API„Å®„ÅÆÈÄ£Êê∫**: ‰ΩøÁî®ËÄÖ„ÅØAnthropic„ÅÆSDK„ÇÑAPI„ÇíÂà©Áî®„Åó„Å¶„ÄÅ„É¢„Éá„É´„Å´„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÈÄÅ‰ø°„Åó„Åü„Çä„ÄÅÂøúÁ≠î„ÇíÂèó„ÅëÂèñ„Å£„Åü„Çä„Åô„Çã„Åì„Å®„Åå„Åß„Åç„Åæ„Åô„ÄÇ\n",
      "\n",
      "#### 4. „Ç≥„Çπ„Éà„Å®Âà∂Èôê\n",
      "- **„Éà„Éº„ÇØ„É≥ÁÆ°ÁêÜ**: „É¢„Éá„É´‰ΩøÁî®„Å´„ÅÇ„Åü„Çä„ÄÅ„Éà„Éº„ÇØ„É≥„ÅÆÊ∂àË≤ª„Çí„É¢„Éã„Çø„É™„É≥„Ç∞„Åó„ÄÅÂäπÁéáÁöÑ„Å™„É™„ÇΩ„Éº„Çπ‰ΩøÁî®„ÇíÂøÉ„Åå„Åë„Çã„Åì„Å®„ÅåÊé®Â•®„Åï„Çå„Åæ„Åô„ÄÇ\n",
      "- **„É¨„Éº„ÉàÂà∂Èôê**: Claude Haiku 4.5„ÅØ„ÄÅ„Ç®„É≥„Çø„Éº„Éó„É©„Ç§„Ç∫„Åä„Çà„Å≥MCA-E„Çµ„Éñ„Çπ„ÇØ„É™„Éó„Ç∑„Éß„É≥Áî®„Å´Ë®≠ÂÆö„Åï„Çå„ÅüÁâπÂÆö„ÅÆ„Éà„Éº„ÇØ„É≥„Åä„Çà„Å≥„É™„ÇØ„Ç®„Çπ„Éà„ÅÆÂà∂Èôê„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ\n",
      "\n",
      "#### 5. ÂÄ´ÁêÜÁöÑ„Å™AI„ÅÆËÄÉÊÖÆ\n",
      "- ‰ΩøÁî®ÊôÇ„Å´„ÅØ„ÄÅAI„Ç≥„É≥„ÉÜ„É≥„ÉÑ„ÅÆÂÆâÂÖ®ÊÄß„ÇíÊßãÊàê„Åó„ÄÅAnthropic„ÅÆÂà©Áî®Ë¶èÁ¥Ñ„Å´Âæì„ÅÜ„Åì„Å®„ÅåÊ±Ç„ÇÅ„Çâ„Çå„Åæ„Åô„ÄÇÁâπ„Å´„ÄÅ„É¢„Éá„É´„ÅÆÊé®Ë´ñÊôÇ„Å´„Ç≥„É≥„ÉÜ„É≥„ÉÑ„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„ÇíË®≠ÂÆö„Åô„Çã„Åì„Å®„ÅåÈáçË¶Å„Åß„Åô„ÄÇ\n",
      "\n",
      "### ÁµêË´ñ\n",
      "Claude Haiku 4.5„ÅØ„ÄÅMicrosoft Foundry„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†‰∏ä„Åß„ÅÆÈ´òÂ∫¶„Å™AIÊ©üËÉΩ„ÇíÊèê‰æõ„Åó„ÄÅ„Éì„Ç∏„Éç„Çπ„Éó„É≠„Çª„Çπ„ÅÆÊúÄÈÅ©Âåñ„ÇÑÂäπÁéáÂåñ„Å´ÂØÑ‰∏é„Åô„Çã„Åì„Å®„ÅåÊúüÂæÖ„Åï„Çå„Åæ„Åô„ÄÇÈñãÁô∫ËÄÖ„ÇÑ‰ºÅÊ•≠„ÅØ„ÄÅ„Åì„ÅÆ„É¢„Éá„É´„ÇíÊ¥ªÁî®„Åô„Çã„Åì„Å®„Åß„ÄÅË§áÈõë„Å™„Çø„Çπ„ÇØ„ÇíÂäπÊûúÁöÑ„Å´Âá¶ÁêÜ„Åó„ÄÅÁ´∂‰∫âÂäõ„ÇíÈ´ò„ÇÅ„Çã„Åì„Å®„ÅåÂèØËÉΩ„Åß„Åô„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_ENDPOINT = os.getenv(\"OPENAI_ENDPOINT\") # ex. https://project1.openai.azure.com/openai/v1/\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_DEPLOYMENT_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=OPENAI_ENDPOINT,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "context = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Microsoft Foundry „Åß„Éõ„Çπ„Éà„Åï„Çå„Çã Anthropic Claud Haiku 4.5 „Å´„Å§„ÅÑ„Å¶Ëß£Ë™¨„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\"\n",
    "    }\n",
    "] \n",
    "\n",
    "response = client.responses.create(\n",
    "    model=MODEL_DEPLOYMENT_NAME,\n",
    "    input=context,\n",
    "    max_output_tokens=1000,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"mcp\",\n",
    "            \"server_label\": \"Microsoft_Learn_MCP_Server\",\n",
    "            \"server_description\": \"Stop AI Hallucinations. Give your AI assistant (Claude, Cursor, Copilot, Codex, ...) direct access to the latest official Microsoft documentation.\",\n",
    "            \"server_url\": \"https://learn.microsoft.com/api/mcp\",\n",
    "            \"require_approval\": \"never\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "    \n",
    "print(json.dumps(response.model_dump(), indent=2, ensure_ascii=False))\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(response.output_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
